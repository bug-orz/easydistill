{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d70547db-79bc-418d-aa3a-c7aeb68e15e2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:19:40.232829Z",
     "iopub.status.busy": "2025-11-08T18:19:40.232447Z",
     "iopub.status.idle": "2025-11-08T18:19:46.940552Z",
     "shell.execute_reply": "2025-11-08T18:19:46.939925Z",
     "shell.execute_reply.started": "2025-11-08T18:19:40.232810Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "temp=load_dataset('/mnt/data/yyh/ChatLearn/dataset/geo3k/')['train']\n",
    "data=[temp[tt] for tt in range(2100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5315aea-253e-46bf-a389-01cff0e2cac8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:19:46.941888Z",
     "iopub.status.busy": "2025-11-08T18:19:46.941632Z",
     "iopub.status.idle": "2025-11-08T18:19:46.945436Z",
     "shell.execute_reply": "2025-11-08T18:19:46.945003Z",
     "shell.execute_reply.started": "2025-11-08T18:19:46.941872Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'hiyouga/geometry3k',\n",
       " 'prompt': [{'role': 'user',\n",
       "   'content': '<image>Find x. You FIRST think about the reasoning process as an internal monologue and then provide the final answer. The reasoning process MUST BE enclosed within <think> </think> tags. The final answer MUST BE put in \\\\boxed{}.'}],\n",
       " 'images': [<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=250x258>],\n",
       " 'ability': 'math',\n",
       " 'reward_model': {'style': 'rule', 'ground_truth': '3'},\n",
       " 'extra_info': {'split': 'train',\n",
       "  'index': 0,\n",
       "  'answer': '3',\n",
       "  'question': '<image>Find x.'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d585e0e-5901-4c96-9e6e-a8b2bec92be7",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:19:46.946445Z",
     "iopub.status.busy": "2025-11-08T18:19:46.946156Z",
     "iopub.status.idle": "2025-11-08T18:19:46.952564Z",
     "shell.execute_reply": "2025-11-08T18:19:46.952118Z",
     "shell.execute_reply.started": "2025-11-08T18:19:46.946430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "def get_index(temp):\n",
    "    return temp['extra_info']['index']\n",
    "\n",
    "def get_answer(temp):\n",
    "    return temp['extra_info']['answer']\n",
    "\n",
    "def get_input(temp):\n",
    "    return temp['images'][0], temp['prompt'][0]['content']\n",
    "\n",
    "import re\n",
    "\n",
    "from mathruler.grader import extract_boxed_content, grade_answer\n",
    "\n",
    "\n",
    "def format_reward(predict_str: str) -> float:\n",
    "    pattern = re.compile(r\"<think>.*</think>.*\\\\boxed\\{.*\\}.*\", re.DOTALL)\n",
    "    match_result = re.fullmatch(pattern, predict_str)\n",
    "    return 1.0\n",
    "    #return 1.0 if match_result else 0.0\n",
    "\n",
    "\n",
    "def acc_reward(predict_str: str, ground_truth: str, use_boxed: bool = True) -> float:\n",
    "    if use_boxed:\n",
    "        answer = extract_boxed_content(predict_str)\n",
    "    else:\n",
    "        answer = predict_str\n",
    "    return 1.0 if grade_answer(answer, ground_truth) else 0.0\n",
    "\n",
    "\n",
    "def get_reward(predict_str: str, ground_truth: str, use_boxed: bool = True, format_score: float = 0.1) -> float:\n",
    "    return acc_reward(predict_str, ground_truth, use_boxed) # + format_score * format_reward(predict_str)\n",
    "\n",
    "def get_gain(reward_list, temp=0.25):\n",
    "    if isinstance(reward_list, torch.Tensor):\n",
    "        reward_array = reward_list.cpu().numpy()\n",
    "    elif isinstance(reward_list, list):\n",
    "        reward_array = np.array(reward_list, dtype=np.float64)\n",
    "    elif isinstance(reward_list, np.ndarray):\n",
    "        reward_array = reward_list\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            f\"Unsupported type for reward_list: {type(reward_list)}. Expected torch.Tensor, list, or np.ndarray.\"\n",
    "        )\n",
    "\n",
    "    reward_array_ct = reward_array - reward_array.max()\n",
    "    reward_array_ctt = reward_array_ct / temp\n",
    "    exp_rewards = np.exp(reward_array_ctt)\n",
    "    soft_dist = exp_rewards / exp_rewards.sum()\n",
    "    return np.sum(soft_dist * reward_array) - reward_array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d2726bf-0a23-45db-9da0-deeb424e494b",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:19:47.700373Z",
     "iopub.status.busy": "2025-11-08T18:19:47.699939Z",
     "iopub.status.idle": "2025-11-08T18:19:47.706667Z",
     "shell.execute_reply": "2025-11-08T18:19:47.706194Z",
     "shell.execute_reply.started": "2025-11-08T18:19:47.700357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def student(img,query):\n",
    "    openai_api_key = \"EMPTY\"\n",
    "    openai_api_base = \"http://localhost:8000/v1\"\n",
    "    client = OpenAI(\n",
    "        api_key=openai_api_key,\n",
    "        base_url=openai_api_base,\n",
    "    )\n",
    "\n",
    "    SYSTEM_PROMPT='''You are a helpful assistant.'''\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")  # 保存为PNG格式到内存\n",
    "    img_bytes = buffer.getvalue()   # 获取字节数据\n",
    "\n",
    "    encoded_image_text = base64.b64encode(img_bytes).decode('utf-8')\n",
    "    #encoded_image_text = encoded_image.decode(\"utf-8\")\n",
    "    base64_qwen = f\"data:image;base64,{encoded_image_text}\"\n",
    "\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"/mnt/data/yyh/RLdistill/models/geo3k_3B/v7/\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": base64_qwen\n",
    "                        },\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": query},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "        n=8,\n",
    "        max_tokens=2048 \n",
    "    )\n",
    "\n",
    "    return [chat_response.choices[i].message.content for i in range(8)]\n",
    "\n",
    "def teacher(img,query):\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")  # 保存为PNG格式到内存\n",
    "    img_bytes = buffer.getvalue()   # 获取字节数据\n",
    "\n",
    "    encoded_image_text = base64.b64encode(img_bytes).decode('utf-8')\n",
    "    #encoded_image_text = encoded_image.decode(\"utf-8\")\n",
    "    base64_qwen = f\"data:image;base64,{encoded_image_text}\"\n",
    "    \n",
    "    api_key=\"sk-\"\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-vl-max-latest\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": base64_qwen\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": query\n",
    "                }\n",
    "            ]\n",
    "        }],\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        stop=[\"</score>\"]  # ← 这里设置 stop tokens\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb37aca0-6362-4767-93c5-5394ea09df5c",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:19:51.715887Z",
     "iopub.status.busy": "2025-11-08T18:19:51.715439Z",
     "iopub.status.idle": "2025-11-08T18:19:58.447795Z",
     "shell.execute_reply": "2025-11-08T18:19:58.447137Z",
     "shell.execute_reply.started": "2025-11-08T18:19:51.715868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2100 [00:04<2:42:00,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gain_1 0.761360223541884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2100 [00:06<3:54:41,  6.71s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pool={}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for dd in tqdm(data):\n",
    "    img,query=get_input(dd)\n",
    "    candidates=student(img,query)\n",
    "    ans=get_answer(dd)\n",
    "    rewards=[get_reward(candidates[kk],ans) for kk in range(8)]\n",
    "    idx=get_index(dd)\n",
    "    gain_1=get_gain(rewards)\n",
    "    \n",
    "    if gain_1>=0.5:\n",
    "        pool[idx]=''\n",
    "        print('gain_1',gain_1)\n",
    "        continue\n",
    "    if sum(rewards)>0:\n",
    "        continue\n",
    "        \n",
    "    ask_hint=f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model’s candidate answer with reasoning: {candidates[0]}\n",
    "\n",
    "    Analyze the student’s reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~90% likely to self-correct and produce the right answer, and ~10% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    hint=teacher(img,ask_hint)\n",
    "    \n",
    "    hint_query=f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates=student(img,hint_query)\n",
    "    rewards=[get_reward(candidates[kk],ans) for kk in range(8)]\n",
    "    gain_2=get_gain(rewards)\n",
    "    \n",
    "    if gain_2>=0.5:\n",
    "        pool[idx]=hint\n",
    "        print('gain_2',gain_2)\n",
    "        continue\n",
    "    if sum(rewards)>0:\n",
    "        continue\n",
    "        \n",
    "    ask_hint=f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model’s candidate answer with reasoning: {candidates[0]}\n",
    "    Previous hint (invalid): {hint}\n",
    "\n",
    "    Analyze the student’s reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~99% likely to self-correct and produce the right answer, and ~1% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    hint=teacher(img,ask_hint)\n",
    "    \n",
    "    hint_query=f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates=student(img,hint_query)\n",
    "    rewards=[get_reward(candidates[kk],ans) for kk in range(8)]\n",
    "    gain_3=get_gain(rewards)\n",
    "    \n",
    "    if gain_3>=0.5:\n",
    "        pool[idx]=hint\n",
    "        print('gain_3',gain_4)\n",
    "        continue\n",
    "    if sum(rewards)>0:\n",
    "        continue\n",
    "        \n",
    "    ask_hint=f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model’s candidate answer with reasoning: {candidates[0]}\n",
    "    Previous hint (invalid): {hint}\n",
    "\n",
    "    Analyze the student’s reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~100% likely to self-correct and produce the right answer, and ~0% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    hint=teacher(img,ask_hint)\n",
    "    \n",
    "    hint_query=f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates=student(img,hint_query)\n",
    "    rewards=[get_reward(candidates[kk],ans) for kk in range(8)]\n",
    "    gain_4=get_gain(rewards)\n",
    "    \n",
    "    if gain_4>=0.5:\n",
    "        pool[idx]=hint\n",
    "        print('gain_4',gain_4)\n",
    "        continue\n",
    "    if sum(rewards)>0:\n",
    "        continue\n",
    "    print('Useless')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecd63e4c-cc53-48da-931d-c255e864c892",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:20:00.288925Z",
     "iopub.status.busy": "2025-11-08T18:20:00.288527Z",
     "iopub.status.idle": "2025-11-08T18:20:00.291802Z",
     "shell.execute_reply": "2025-11-08T18:20:00.291217Z",
     "shell.execute_reply.started": "2025-11-08T18:20:00.288907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visited={}\n",
    "pool = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c396ab-f819-4805-b211-915ecabcc08d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:20:21.559391Z",
     "iopub.status.busy": "2025-11-08T18:20:21.559023Z",
     "iopub.status.idle": "2025-11-08T18:48:33.804578Z",
     "shell.execute_reply": "2025-11-08T18:48:33.803987Z",
     "shell.execute_reply.started": "2025-11-08T18:20:21.559372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [28:11<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "\n",
    "def process_item(dd):\n",
    "    \n",
    "    idx = get_index(dd)\n",
    "    \n",
    "    if visited.get(idx):\n",
    "        if pool.get(idx):\n",
    "            return idx, pool[idx]\n",
    "        else:\n",
    "            return idx, None\n",
    "    else:\n",
    "        visited[idx]=''\n",
    "    \n",
    "    img, query = get_input(dd)\n",
    "    \n",
    "    candidates = student(img, query)\n",
    "    ans = get_answer(dd)\n",
    "    rewards = [get_reward(candidates[kk], ans) for kk in range(8)]\n",
    "    \n",
    "    gain_1 = get_gain(rewards)\n",
    "    \n",
    "    if gain_1 >= 0.1:\n",
    "        return idx, ''\n",
    "    if sum(rewards) > 0:\n",
    "        return idx, None\n",
    "        \n",
    "    ask_hint = f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model's candidate answer with reasoning: {candidates[0]}\n",
    "\n",
    "    Analyze the student's reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~30% likely to self-correct and produce the right answer, and ~70% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hint = teacher(img, ask_hint)\n",
    "    except:\n",
    "        return idx, None\n",
    "    \n",
    "    hint_query = f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates = student(img, hint_query)\n",
    "    rewards = [get_reward(candidates[kk], ans) for kk in range(8)]\n",
    "    gain_2 = get_gain(rewards)\n",
    "    \n",
    "    if gain_2 >= 0.1:\n",
    "        return idx, hint\n",
    "    if sum(rewards) > 0:\n",
    "        return idx, None\n",
    "        \n",
    "    ask_hint = f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model's candidate answer with reasoning: {candidates[0]}\n",
    "    Previous hint (invalid): {hint}\n",
    "\n",
    "    Analyze the student's reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~80% likely to self-correct and produce the right answer, and ~20% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hint = teacher(img, ask_hint)\n",
    "    except:\n",
    "        return idx, None\n",
    "    \n",
    "    hint_query = f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates = student(img, hint_query)\n",
    "    rewards = [get_reward(candidates[kk], ans) for kk in range(8)]\n",
    "    gain_3 = get_gain(rewards)\n",
    "    \n",
    "    if gain_3 >= 0.1:\n",
    "        return idx, hint\n",
    "    if sum(rewards) > 0:\n",
    "        return idx, None\n",
    "        \n",
    "    ask_hint = f\"\"\"\n",
    "    Given the following:\n",
    "\n",
    "    Original query: {query}\n",
    "    Reference answer: {ans}\n",
    "    Student model's candidate answer with reasoning: {candidates[0]}\n",
    "    Previous hint (invalid): {hint}\n",
    "\n",
    "    Analyze the student's reasoning process and identify where it goes wrong or becomes misleading. Generate a strong, direct hint that corrects or redirects the flawed reasoning — without revealing the final answer. The hint must be appendable verbatim to the original query, contain NO irrelevant text or answer leakage, and when added, should make the student model ~99% likely to self-correct and produce the right answer, and ~1% likely to still fail — calibrated to encourage reasoning repair, not answer copying. Output ONLY the hint text, nothing else.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hint = teacher(img, ask_hint)\n",
    "    except:\n",
    "        return idx, None\n",
    "    \n",
    "    hint_query = f\"\"\"\n",
    "    ### Query\n",
    "    {query}\n",
    "    ### Hint\n",
    "    {hint}\n",
    "    \"\"\"\n",
    "    candidates = student(img, hint_query)\n",
    "    rewards = [get_reward(candidates[kk], ans) for kk in range(8)]\n",
    "    gain_4 = get_gain(rewards)\n",
    "    \n",
    "    if gain_4 >= 0.1:\n",
    "        return idx, hint\n",
    "    if sum(rewards) > 0:\n",
    "        return idx, None\n",
    "    \n",
    "    return idx, None\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_data = {executor.submit(process_item, dd): dd for dd in data}\n",
    "    \n",
    "    # Process completed tasks with progress bar\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_data), total=len(data)):\n",
    "        idx, hint = future.result()\n",
    "        if hint is not None:\n",
    "            pool[idx] = hint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeb76865-e6d5-44ef-bac2-a5432c51974e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T18:57:48.864523Z",
     "iopub.status.busy": "2025-11-08T18:57:48.864122Z",
     "iopub.status.idle": "2025-11-08T18:57:49.018323Z",
     "shell.execute_reply": "2025-11-08T18:57:49.017845Z",
     "shell.execute_reply.started": "2025-11-08T18:57:48.864503Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af20a1aba7bd4a0fb7d0623689f513f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "16083189"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个函数来修改特定样本\n",
    "def modify_prompt(example,idx):\n",
    "    origin_content=get_input(example)[1]\n",
    "    if pool.get(get_index(example)):\n",
    "        if len(pool[get_index(example)])>0:\n",
    "            example['prompt'][0]['content']=f\"\"\"### Query\n",
    "{origin_content}\n",
    "### Hint\n",
    "{pool[get_index(example)]}\n",
    "            \"\"\"\n",
    "    return example\n",
    "\n",
    "def filter_condition(example, idx):\n",
    "    if pool.get(get_index(example)):\n",
    "        return True\n",
    "    return False  # 这里替换成您的实际条件\n",
    "\n",
    "# 过滤数据集\n",
    "from datasets import load_dataset\n",
    "dataset=load_dataset('/mnt/data/yyh/ChatLearn/dataset/geo3k/')['train']\n",
    "\n",
    "modified_dataset = dataset.map(modify_prompt, with_indices=True)\n",
    "\n",
    "modified_dataset = modified_dataset.filter(filter_condition, with_indices=True)\n",
    "\n",
    "from datasets import Features, Sequence, Value, Image\n",
    "\n",
    "# 定义正确的 features 结构（重点：用 Sequence 替代 List）\n",
    "features = Features(\n",
    "    {\n",
    "        \"data_source\": Value(\"string\"),\n",
    "        \"prompt\": [{\"role\": Value(\"string\"), \"content\": Value(\"string\")}],\n",
    "        # images 原来是 List(Image())，这里改成 Sequence(Image())\n",
    "        \"images\": Sequence(Image()),\n",
    "        \"ability\": Value(\"string\"),\n",
    "        \"reward_model\": {\n",
    "            \"style\": Value(\"string\"),\n",
    "            \"ground_truth\": Value(\"string\"),\n",
    "        },\n",
    "        \"extra_info\": {\n",
    "            \"split\": Value(\"string\"),\n",
    "            \"index\": Value(\"int64\"),\n",
    "            \"answer\": Value(\"string\"),\n",
    "            \"question\": Value(\"string\"),\n",
    "        },\n",
    "    }\n",
    ")\n",
    "# 强制转换类型\n",
    "modified_dataset = modified_dataset.cast(features)\n",
    "\n",
    "modified_dataset.to_parquet(\"/mnt/data/yyh/ChatLearn/dataset/CVPR/geo3k_3B/v8/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a8b5f89-1deb-4f9b-8132-1a62a8093f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T18:57:55.034804Z",
     "iopub.status.busy": "2025-11-08T18:57:55.034077Z",
     "iopub.status.idle": "2025-11-08T18:57:55.038002Z",
     "shell.execute_reply": "2025-11-08T18:57:55.037532Z",
     "shell.execute_reply.started": "2025-11-08T18:57:55.034784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modified_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
